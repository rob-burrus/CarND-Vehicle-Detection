{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Conv2D, Flatten, Lambda, MaxPooling2D, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pickle_data():\n",
    "    basedir = 'vehicles/'\n",
    "    image_types = os.listdir(basedir)\n",
    "    cars = []\n",
    "    for imtype in image_types:\n",
    "        cars.extend(glob.glob(basedir+imtype+'/*'))\n",
    "    print ('Number of Vehicle Images found: ', len(cars))\n",
    "    with open('cars.txt', 'w') as f:\n",
    "        for fn in cars:\n",
    "            f.write(fn + '\\n')\n",
    "\n",
    "    basedir = 'non-vehicles/'\n",
    "    image_types = os.listdir(basedir)\n",
    "    notcars = []\n",
    "    for imtype in image_types:\n",
    "        notcars.extend(glob.glob(basedir+imtype+'/*'))\n",
    "    print ('Number of Non-Vehicle Images found: ', len(notcars))\n",
    "    with open('non-cars.txt', 'w') as f:\n",
    "        for fn in notcars:\n",
    "            f.write(fn + '\\n')\n",
    "    \n",
    "    files = cars + notcars\n",
    "    y = np.concatenate((np.ones(len(cars)), np.zeros(len(notcars))))\n",
    "\n",
    "    files, y = shuffle(files, y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(files, y, test_size=0.2, random_state=19)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=19)\n",
    "\n",
    "    data = {'X_train': X_train, \n",
    "            'X_val': X_val, \n",
    "            'X_test': X_test,\n",
    "            'y_train': y_train, \n",
    "            'y_val': y_val, \n",
    "            'y_test': y_test}\n",
    "\n",
    "    pickle.dump(data, open('data.p', 'wb'))\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_data():\n",
    "    if not os.path.isfile('data.p'):\n",
    "        pickle_data()\n",
    "\n",
    "    with open('data.p', mode='rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        X_train = data['X_train']\n",
    "        X_test = data['X_test']\n",
    "        X_val = data['X_val']\n",
    "        y_train = data['y_train']\n",
    "        y_val = data['y_val']\n",
    "        y_test = data['y_test']\n",
    "        \n",
    "    return np.array(X_train), np.array(X_val), np.array(X_test), np.array(y_train), np.array(y_val), np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_images(img_paths, labels):\n",
    "    #print(\"Here\")\n",
    "    imgs = np.empty([128, 64, 64, 3])\n",
    "    for i,path in enumerate(img_paths):\n",
    "        #print(\"Image path:{}\".format(path))\n",
    "        imgs[i] = cv2.imread(path)\n",
    "        \n",
    "    return imgs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate(x, y, batch_size):\n",
    "    size = len(x)\n",
    "    while True:\n",
    "        rng = np.random.choice(size, batch_size)\n",
    "        x_batch, y_batch = get_images(x[rng], y[rng])\n",
    "        yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inputShape = (64, 64, 3)\n",
    "    model = Sequential()\n",
    "    #model.add(Lambda(lambda x: x / 127.5 - 1, input_shape=(64, 64, 3)))\n",
    "    #model.add(Convolution2D(16, 3, 3, input_shape=(64,64,3), activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(8, 8)))\n",
    "    #model.add(Flatten())\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(50))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(1))\n",
    "    model = Sequential()\n",
    "    # Center and normalize our data\n",
    "    model.add(Lambda(lambda x: x / 255., input_shape=inputShape))\n",
    "    # Block 0\n",
    "    model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', name='cv0', input_shape=inputShape, padding=\"same\"))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Block 1\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', name='cv1', padding=\"same\"))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # block 2\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', name='cv2', padding=\"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(8, 8)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # binary 'classifier'\n",
    "    model.add(Conv2D(filters=1, kernel_size=(8, 8), name='fcn', activation=\"sigmoid\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'nb_filter', 'nb_row', and 'nb_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-3998442f700b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(\"data loaded\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msourceModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msourceModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-d51241c04892>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputShape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Block 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cv0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputShape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'nb_filter', 'nb_row', and 'nb_col'"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = load_data()\n",
    "\n",
    "#print(\"data loaded\")\n",
    "\n",
    "sourceModel = get_model()\n",
    "\n",
    "x = sourceModel.output\n",
    "x = Flatten()(x)\n",
    "model = Model(inputs=sourceModel.input, outputs=x)\n",
    "        \n",
    "#print(model.summary())\n",
    "\n",
    "# Train the Model\n",
    "model.compile('adam', 'mse', metrics=['accuracy'])\n",
    "\n",
    "train_gen = generate(X_train, y_train, 128)\n",
    "valid_gen = generate(X_val, y_val, 128)\n",
    "history = model.fit_generator(train_gen,\n",
    "                              nb_epoch=4,\n",
    "                              samples_per_epoch=(len(X_train)//128)*128,\n",
    "                              validation_data=valid_gen,\n",
    "                              nb_val_samples=(len(X_val)//128)*128,\n",
    "                              verbose=1)\n",
    "\n",
    "# Save the Model\n",
    "model.save('model_{}.h5'.format(datetime.now()))\n",
    "\n",
    "print('Evaluating accuracy on test set.')\n",
    "\n",
    "accuracy = model.evaluate_generator(generator=generate(X_test, y_test, 128), val_samples=(len(X_test)//128)*128)\n",
    "\n",
    "print('test accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
